# Landmark and Important Papers by Topic

## 1. SLAM (Simultaneous Localization and Mapping)

### Landmark Papers
- **["A Solution to the Simultaneous Localization and Map Building (SLAM) Problem"](https://ieeexplore.ieee.org/document/299758)** - Smith & Cheeseman (1986)
  - Foundational work using Extended Kalman Filter (EKF) for SLAM formulation
  
- **["Past, Present, and Future of Simultaneous Localization And Mapping: Towards the Robust-Perception Age"](https://ieeexplore.ieee.org/document/1578022)** - Durrant-Whyte & Bailey (2006)
  - Comprehensive survey of SLAM methods and transition to industry applications
  
- **["ORB-SLAM: a Versatile and Accurate Monocular SLAM System"](https://arxiv.org/abs/1502.00956)** - Murillo & Tardós
  - State-of-the-art monocular visual SLAM system

### Important Branch Papers
- **["Mono-SLAM: Single Camera SLAM"](https://ieeexplore.ieee.org/document/4160954)** - Davison et al. (2007)
  - First real-time monocular SLAM system
  
- **["Parallel Tracking and Mapping for Real-time Monocular SLAM"](https://ieeexplore.ieee.org/document/4538852)** - Klein et al. (2007)
  - Multi-threading approach for efficient SLAM

### SOTA Papers
- **["Beyond Implicit Representations: Exploring Gaussian Splatting for Next-Generation SLAM"](https://arxiv.org/search/?query=gaussian+splatting+slam&searchtype=all)** (2025)
  - Integration of 3D Gaussian Splatting with SLAM frameworks
  
- **["How NeRFs and 3D Gaussian Splatting are Reshaping SLAM: a Survey"](https://arxiv.org/search/?query=nerf+gaussian+splatting+slam+survey)** (2024)
  - Latest advances in neural rendering for SLAM

### Relevant Surveys/Articles
- **["Monocular Visual SLAM: Evolution from Geometry to Deep Learning-Based Pipelines"](https://arxiv.org/search/?query=monocular+visual+slam+deep+learning)** (2025)
- **["Visual SLAM: What Are the Current Trends and What to Expect?"](https://arxiv.org/search/?query=visual+slam+trends)** (2022)
- **["Semantic Visual SLAM: A Survey"](https://arxiv.org/search/?query=semantic+visual+slam+survey)** (2022)
- **["Active SLAM: A Review on Last Decade"](https://arxiv.org/search/?query=active+slam+review)** (2023)

---

## 2. Visual SLAM (vSLAM)

### Landmark Papers
- **["ORB-SLAM2: an Open-Source SLAM System for Monocular, Stereo, and RGB-D Cameras"](https://arxiv.org/abs/1610.00889)** - Murillo & Tardós (2015)
  - Extended ORB-SLAM to multiple camera types

### Important Branch Papers
- **["PL-SLAM: A Stereo SLAM System through the Combination of Points and Line Segments"](https://arxiv.org/search/?query=pl-slam+stereo)** - Gomez-Ojeda et al.
  - Point and line-based visual SLAM

### SOTA Papers
- **["Semantic vSLAM with Deep Learned Mapping and Semantic Loop Closure Detection"](https://arxiv.org/search/?query=semantic+vslam+deep+learning)** 
- **["D²SLAM: Decentralized and Distributed Collaborative Visual-Inertial SLAM System for Aerial Swarm"](https://arxiv.org/abs/2211.01538)** (2024)

---

## 3. CNN (Convolutional Neural Networks)

### Landmark Papers
- **["ImageNet Classification with Deep Convolutional Neural Networks"](https://papers.neurips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)** - Krizhevsky, Sutskever & Hinton (2012)
  - **AlexNet**: Revolutionary work that sparked deep learning renaissance
  
- **["Very Deep Convolutional Networks for Large-Scale Image Recognition"](https://arxiv.org/abs/1409.1556)** - Simonyan & Zisserman (2014)
  - **VGGNet**: Systematic study of CNN depth
  
- **["Deep Residual Learning for Image Recognition"](https://arxiv.org/abs/1512.03385)** - He et al. (2015)
  - **ResNet**: Breakthrough in training very deep networks with residual connections
  
- **["Going Deeper with Convolutions"](https://arxiv.org/abs/1409.4842)** - Szegedy et al. (2014)
  - **GoogLeNet/Inception**: Multi-scale convolutional architecture

### Important Branch Papers
- **["LeNet-5"](https://yann.lecun.com/exdb/lenet/)** - LeCun et al.
  - Early foundational CNN work
  
- **["Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"](https://arxiv.org/abs/1502.03167)** - Ioffe & Szegedy (2015)
  - Fundamental technique for training CNNs

### SOTA Papers
- **["ConvNeXt: A ConvNet for the 2020s"](https://arxiv.org/abs/2201.03545)** (2022)
  - Modern CNN architecture combining classical and modern techniques

---

## 4. Vision Transformer (ViT)

### Landmark Papers
- **["An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"](https://arxiv.org/abs/2010.11929)** - Dosovitskiy et al. (2020)
  - **Vision Transformer (ViT)**: First successful application of pure transformer architecture to vision
  
- **["Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"](https://arxiv.org/abs/2103.14030)** - Liu et al. (2021)
  - Hierarchical vision transformers with local attention

### Important Branch Papers
- **["DeiT: Data-efficient image Transformers"](https://arxiv.org/abs/2012.12556)** - Touvron et al. (2020)
  - Improved training strategies for ViT
  
- **["Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"](https://arxiv.org/abs/2101.11605)** - Yuan et al. (2021)
  - Progressive tokenization for efficient ViT

### SOTA Papers
- **["DeepViT: Towards Deeper Vision Transformer"](https://arxiv.org/abs/2103.11886)** (2021)
- **["Intriguing Properties of Vision Transformers"](https://arxiv.org/abs/2105.07538)** (2021)
- **["LF-ViT: Reducing Spatial Redundancy in Vision Transformer"](https://arxiv.org/abs/2401.13960)** (2024)

### Relevant Surveys/Articles
- **["Recent Advances in Vision Transformer: A Survey and Outlook"](https://arxiv.org/abs/2203.01536)** (2022)
- **["Enhancing Efficiency in Vision Transformer Networks"](https://arxiv.org/search/?query=vision+transformer+efficiency)** (2024)

---

## 5. 2D Object Detection

### Landmark Papers
- **["Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"](https://arxiv.org/abs/1506.01497)** - Ren et al. (2015)
  - Foundational two-stage detector with RPN
  
- **["You Only Look Once: Unified, Real-Time Object Detection"](https://arxiv.org/abs/1506.02640)** - Redmon et al. (2015)
  - First single-stage real-time detector
  
- **["SSD: Single Shot MultiBox Detector"](https://arxiv.org/abs/1512.02325)** - Liu et al. (2015)
  - Single-stage detector with multi-scale feature maps

### Important Branch Papers
- **["Rich feature hierarchies for accurate object detection and semantic segmentation"](https://arxiv.org/abs/1311.2524)** - Girshick et al. (2013)
  - Original region-based CNN approach (R-CNN)
  
- **["Fast R-CNN"](https://arxiv.org/abs/1504.08083)** - Girshick (2015)
  - Improved R-CNN with shared computation

### SOTA Papers
- **["YOLOv4: Optimal Speed and Accuracy of Object Detection"](https://arxiv.org/abs/2004.10934)** (2020)
- **["YOLOv5/v8"](https://github.com/ultralytics/yolov5)** - Latest YOLO variants
- **["Cascade R-CNN: Delving into High Quality Object Detection"](https://arxiv.org/abs/1712.00726)** (2017)

---

## 6. 2D Object Tracking

### Landmark Papers
- **["Simple Online and Realtime Tracking"](https://arxiv.org/abs/1602.00763)** - Bewley et al. (2016)
  - Efficient multi-object tracking using Kalman filter and Hungarian algorithm
  
- **["The Hungarian Algorithm and Its Generalizations"](https://www.jstor.org/stable/2308328)** - Kuhn (1955)
  - Classic matching algorithm used in tracking

### Important Branch Papers
- **["Simple Online and Realtime Tracking with a Deep Association Metric"](https://arxiv.org/abs/1703.07402)** - Wojke et al. (2017)
  - Deep learning-based appearance features for tracking (Deep SORT)

### SOTA Papers
- **["ByteTrack: Multi-Object Tracking by Associating Every Detection Box"](https://arxiv.org/abs/2110.06864)** (2021)

### Relevant Articles
- **["An Analysis of Kalman Filter based Object Tracking Methods for Fast Moving Objects"](https://arxiv.org/search/?query=kalman+filter+object+tracking)** (2025)

---

## 7. 2D Segmentation

### Landmark Papers
- **["Fully Convolutional Networks for Semantic Segmentation"](https://arxiv.org/abs/1411.4038)** - Long et al. (2014)
  - **FCN**: Foundational pixel-wise segmentation architecture
  
- **["U-Net: Convolutional Networks for Biomedical Image Segmentation"](https://arxiv.org/abs/1505.04597)** - Ronneberger et al. (2015)
  - Encoder-decoder architecture with skip connections
  
- **["DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs"](https://arxiv.org/abs/1606.00915)** - Chen et al. (2016)
  - Atrous convolution and CRF for dense prediction
  
- **["Segmenter: Transformer for Semantic Segmentation"](https://arxiv.org/abs/2105.05633)** - Strudel et al. (2021)
  - Vision Transformer applied to semantic segmentation

### Important Branch Papers
- **["The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation"](https://arxiv.org/abs/1611.09326)** - Jégou et al. (2016)
  - DenseNet architecture for segmentation
  
- **["Dual Attention Network for Scene Segmentation"](https://arxiv.org/abs/1809.02983)** - Fu et al. (2019)
  - Spatial and channel attention for segmentation

### SOTA Papers
- **["SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"](https://arxiv.org/abs/2105.03722)** (2021)
- **["Prototype-Based Semantic Segmentation"](https://arxiv.org/search/?query=prototype+semantic+segmentation)** (2024)

---

## 8. 3D Object Detection

### Landmark Papers
- **["PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation"](https://arxiv.org/abs/1612.00593)** - Qi et al. (2016)
  - First end-to-end deep learning on raw point clouds
  
- **["PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space"](https://arxiv.org/abs/1706.02413)** - Qi et al. (2017)
  - Hierarchical point cloud processing
  
- **["PointPillars: Fast Encoders for Object Detection from Point Clouds"](https://arxiv.org/abs/1812.05796)** - Lang et al. (2018)
  - Fast 3D detection using pillar-based encoding

### Important Branch Papers
- **["VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection"](https://arxiv.org/abs/1711.08488)** - Zhou & Tuzel (2017)
  - Voxel-based 3D detection
  
- **["SECOND: Sparsely Embedded Convolutional Detection"](https://arxiv.org/abs/1809.05895)** - Yan et al. (2018)
  - Sparse 3D convolutions

### SOTA Papers
- **["3DPillars: Pillar-Based Two-Stage 3D Object Detection"](https://arxiv.org/search/?query=3d+pillars+object+detection)** (2024)
- **["Existence Map-PointPillars"](https://arxiv.org/search/?query=existence+map+pointpillars)** (2023)

---

## 9. 3D Reconstruction (3DGS and NeRF)

### Landmark Papers - NeRF
- **["NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis"](https://arxiv.org/abs/2003.08934)** - Mildenhall et al. (2020)
  - Revolutionary neural rendering approach using implicit representation
  
- **["Instant Neural Graphics Primitives with a Multiresolution Hash Encoding"](https://arxiv.org/abs/2201.05989)** - Müller et al. (2022)
  - **Instant NeRF**: Significantly faster NeRF training

### Landmark Papers - 3D Gaussian Splatting
- **["3D Gaussian Splatting for Real-Time Radiance Field Rendering"](https://arxiv.org/abs/2308.04079)** - Kerbl et al. (2023)
  - Breakthrough in real-time 3D scene reconstruction
  - Won best paper at SIGGRAPH 2023

### Important Branch Papers
- **["Deferred Neural Rendering: Image Synthesis using Neural Textures"](https://arxiv.org/abs/1906.12882)** - Thies et al. (2019)
  - Combining graphics pipeline with learned components
  
- **["Neural Radiance Fields for View Synthesis"](https://arxiv.org/abs/2008.12847)** - Sitzmann et al. (2021)
  - Light field networks and fast 3D scene representation

### SOTA Papers
- **["Neuralangelo: High-Fidelity Neural Surface Reconstruction"](https://arxiv.org/search/?query=neuralangelo+surface+reconstruction)** - NVIDIA Research (2023)
- **["3D Gaussian Splatting against Moving Objects"](https://arxiv.org/search/?query=gaussian+splatting+moving+objects)** (2025)

---

## 10. Structure from Motion (SfM)

### Landmark Papers
- **["Multiple View Geometry in Computer Vision"](https://www.robots.ox.ac.uk/~vgg/work/view_geometry.html)** - Hartley & Zisserman
  - Foundational work on multi-view geometry
  
- **["An Invitation to 3-D Vision: From Images to Geometric Models"](https://link.springer.com/book/10.1007/978-0-387-21779-6)** - Ma, Kosecká, et al.
  - Comprehensive treatment of 3D reconstruction

### Important Branch Papers
- **["Building Rome in a Day"](https://arxiv.org/abs/0905.3494)** - Agarwal et al. (2009)
  - Large-scale SfM system
  
- **["Random Sample Consensus: A Paradigm for Model Fitting"](https://www.jstor.org/stable/2344614)** - Fischler & Bolles (1981)
  - Robust fitting algorithm widely used in SfM

### SOTA Papers
- **["SfM on-the-fly: Get Better 3D from What You Capture"](https://arxiv.org/search/?query=sfm+structure+from+motion+real+time)** (2024)

---

## 11. 3D Scene Editing

### Landmark Papers
- **["Deferred Neural Rendering: Image Synthesis using Neural Textures"](https://arxiv.org/abs/1906.12882)** - Thies et al. (2019)
  - Framework for scene editing with neural representations

### Important Branch Papers
- **["Neural Textures for Realistic Image-Based Rendering"](https://arxiv.org/search/?query=neural+textures+rendering)** - Thies et al. (2019)

### SOTA Papers
- Scene editing typically uses NeRF/3DGS variants

---

## 12. 3D Segmentation

### Landmark Papers
- **["PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation"](https://arxiv.org/abs/1612.00593)** - Qi et al. (2016)
  - Foundational work for point cloud segmentation
  
- **["PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space"](https://arxiv.org/abs/1706.02413)** - Qi et al. (2017)
  - Hierarchical segmentation

### Important Branch Papers
- **["Dynamic Graph CNN for Learning on Point Clouds"](https://arxiv.org/abs/1801.07829)** - Wang et al. (2019)
  - Graph-based point cloud processing
  
- **["DGCNN: Dynamic Graph CNN"](https://arxiv.org/search/?query=dynamic+graph+cnn+point+clouds)** 
  - Advanced graph convolutional approach

### SOTA Papers
- **["Few-Shot 3D Point Cloud Semantic Segmentation"](https://arxiv.org/search/?query=few+shot+3d+point+cloud+segmentation)** (2021)
- **["TLSNet: Key Point Cloud Semantic Segmentation"](https://arxiv.org/search/?query=tlsnet+point+cloud+segmentation)** (2025)
- **["Multi-scale Sparse Convolution for LiDAR Semantic Segmentation"](https://arxiv.org/search/?query=multi+scale+sparse+convolution+lidar)** (2025)

---

## 13. 3D Scene Knowledge Graph

### Landmark Papers
- **["3D Scene Graph: A Structure for Unified Semantics, 3D Space, and Camera"](https://arxiv.org/abs/1910.02527)** - Armeni et al. (2019)
  - Foundational work on 3D scene graphs for holistic scene understanding

### Important Branch Papers
- **["Informing 3D Scene Graph Generation with Common-Sense Spatial Knowledge"](https://arxiv.org/abs/2306.02968)** - Strader et al. (2023)
  - Integration of semantic knowledge in scene graphs

---

## 14. Large Language Models (LLMs)

### Landmark Papers
- **["Attention Is All You Need"](https://arxiv.org/abs/1706.03762)** - Vaswani et al. (2017)
  - Transformer architecture - foundation of all modern LLMs
  
- **["BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"](https://arxiv.org/abs/1810.04805)** - Devlin et al. (2018)
  - Bidirectional pre-training paradigm
  
- **["Language Models are Unsupervised Multitask Learners"](https://openai.com/research/language-models-are-unsupervised-multitask-learners)** - Radford et al. (2019)
  - **GPT-2**: Large-scale language model demonstrating multitask capabilities
  
- **["Language Models are Few-Shot Learners"](https://arxiv.org/abs/2005.14165)** - Brown et al. (2020)
  - **GPT-3**: Few-shot learning in LLMs
  
- **["Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"](https://arxiv.org/abs/1910.10683)** - Raffel et al. (2019)
  - **T5**: Unified text-to-text framework

### Important Branch Papers
- **["XLNet: Generalized Autoregressive Pretraining for Language Understanding"](https://arxiv.org/abs/1906.08237)** - Yang et al. (2019)
- **["RoBERTa: A Robustly Optimized BERT Pretraining Approach"](https://arxiv.org/abs/1907.11692)** - Liu et al. (2019)
- **["ERNIE: Enhanced Representation through Knowledge Integration"](https://arxiv.org/abs/1904.09223)** - Sun et al. (2019)

### SOTA Papers
- **["GPT-4"](https://openai.com/research/gpt-4)** - OpenAI (2023)
- **["Llama 2: Open Foundation and Fine-Tuned Chat Models"](https://arxiv.org/abs/2307.09288)** - Touvron et al. (2023)
- **["Claude 3"](https://www.anthropic.com/news/claude-3-family)** - Anthropic (2024)

---

## 15. Vision-Language Models (VLM)

### Landmark Papers
- **["Learning Transferable Visual Models From Natural Language Supervision"](https://arxiv.org/abs/2103.14030)** - Radford et al. (2021)
  - **CLIP**: Foundational contrastive vision-language learning
  
- **["Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"](https://arxiv.org/abs/2102.05095)** - Jia et al. (2021)
  - **ALIGN**: Large-scale vision-language alignment

### Important Branch Papers
- **["BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"](https://arxiv.org/abs/2201.12086)** - Li et al. (2022)
  - Unified framework for various vision-language tasks
  
- **["Zero-Shot Text-to-Image Generation"](https://arxiv.org/abs/2102.12092)** - Ramesh et al. (2021)
  - **DALL-E**: Text-to-image generation

### SOTA Papers
- **["HQ-CLIP: Leveraging Large Vision-Language Models to Create High-Quality Image-Text Datasets"](https://arxiv.org/search/?query=hq+clip+vision+language)** (2025)
- **["ClearCLIP: Decomposing CLIP Representations for Dense Vision-Language Inference"](https://arxiv.org/search/?query=clearclip+decomposing+representations)** (2024)
- **["Vision-Language Models Do Not Understand Negation"](https://arxiv.org/search/?query=vision+language+models+negation)** (2025)

---

## 16. Fine-Tuning Techniques (LLM, Vision Models)

### Landmark Papers
- **["LoRA: Low-Rank Adaptation of Large Language Models"](https://arxiv.org/abs/2106.09685)** - Hu et al. (2021)
  - Parameter-efficient fine-tuning using low-rank decomposition

### Important Branch Papers
- **["Prefix Tuning: Optimizing Continuous Prompts for Generation"](https://arxiv.org/abs/2101.00190)** - Li & Liang (2021)
  - Prompt-based fine-tuning
  
- **["The Power of Scale for Parameter-Efficient Prompt Tuning"](https://arxiv.org/abs/2104.08691)** - Lester et al. (2021)
  - Prompt tuning for language models
  
- **["QLoRA: Efficient Finetuning of Quantized LLMs"](https://arxiv.org/abs/2305.14314)** - Dettmers et al. (2023)
  - Quantized LoRA for memory efficiency

### SOTA Papers
- **["Parameter-Efficient Transfer Learning for NLP"](https://arxiv.org/abs/1902.00751)** - Houlsby et al. (2019)
- **["PERL: Parameter-Efficient Reinforcement Learning from Human Feedback"](https://arxiv.org/search/?query=perl+parameter+efficient+rl)** (2024)

### Relevant Articles
- **["Fine-Tuning Large Language Models for Specialized Use Cases"](https://arxiv.org/search/?query=fine+tuning+llm+specialized)** (2024)

---

## 17. Reinforcement Learning for Robotics

### Landmark Papers
- **["Playing Atari with Deep Reinforcement Learning"](https://arxiv.org/abs/1312.5602)** - Mnih et al. (2013)
  - **DQN**: Deep Q-Networks breakthrough
  
- **["Continuous Control with Deep Reinforcement Learning"](https://arxiv.org/abs/1509.02971)** - Lillicrap et al. (2015)
  - **DDPG**: Actor-critic for continuous control
  
- **["Proximal Policy Optimization Algorithms"](https://arxiv.org/abs/1707.06347)** - Schulman et al. (2017)
  - **PPO**: State-of-the-art policy gradient method
  
- **["Asynchronous Methods for Deep Reinforcement Learning"](https://arxiv.org/abs/1602.01783)** - Mnih et al. (2016)
  - **A3C**: Parallel policy gradient learning

### Important Branch Papers
- **["Deep Reinforcement Learning from Human Preferences"](https://arxiv.org/abs/1706.03741)** - Christiano et al. (2017)
- **["Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments"](https://arxiv.org/abs/1706.02275)** - Lowe et al. (2017)
  - Multi-agent coordination (MADDPG)

### SOTA Papers
- **["Deep Reinforcement Learning for Robotics: A Survey of Real-World Successes"](https://arxiv.org/search/?query=deep+reinforcement+learning+robotics+survey)** (2024)

---

## 18. Reinforcement Learning for Models (LLM, VLM)

### Landmark Papers
- **["Learning from Human Preferences"](https://arxiv.org/abs/1706.03741)** - Christiano et al. (2017)
  - Preference-based learning
  
- **["Fine-Tuning Language Models from Human Preferences"](https://arxiv.org/abs/1909.08383)** - Ziegler et al. (2019)
  - **RLHF**: Training Language Models to Follow Instructions with Human Feedback (extended by Ouyang et al. 2022)
  
- **["Direct Preference Optimization: Your Language Model is Secretly a Reward Model"](https://arxiv.org/abs/2305.18290)** - Rafailov et al. (2023)
  - Alternative to RLHF

### SOTA Papers
- **["Improve Vision Language Model Chain-of-Thought Reasoning"](https://arxiv.org/search/?query=vision+language+chain+of+thought)** (2024)
- **["Using Implicit Behavior Cloning and DMP for RL in Robot Motion Planning"](https://arxiv.org/search/?query=behavior+cloning+dmp+robot+motion)** (2024)

---

## 19. World Models

### Landmark Papers
- **["World Models"](https://arxiv.org/abs/1803.10122)** - Ha & Schmidhuber (2018)
  - Generative model learning latent dynamics
  
- **["Dream to Control: Learning Behaviors by Latent Imagination"](https://arxiv.org/abs/1912.01603)** - Hafner et al. (2019)
  - **Dreamer**: Planning in learned latent world models
  
- **["Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model"](https://arxiv.org/abs/1805.12377)** - Hafner et al. (2020)
  - **DreamerV2**: Improved world model architecture

### Important Branch Papers
- **["Learning Latent Dynamics for Robot Control"](https://arxiv.org/abs/1811.02223)** - Levine et al. (2018)
- **["Planning to Explore via Self-Supervised World Models"](https://arxiv.org/abs/2005.05960)** - Hafner et al. (2020)
  - **PlaNet**: Learning Latent Dynamics for Planning

### SOTA Papers
- **["Simplifying Latent Dynamics with Softly State-Invariant World Models"](https://arxiv.org/search/?query=softly+state+invariant+world+models)** (2024)
- **["Dynamics-Aligned Latent Imagination in Contextual World Models"](https://arxiv.org/search/?query=dynamics+aligned+latent+imagination)** (2025)
- **["Learning Hierarchical World Models with Adaptive Temporal Abstractions"](https://arxiv.org/search/?query=hierarchical+world+models+temporal)** (2024)
- **["UniZero: Generalized and Efficient Planning with Scalable Latent World Models"](https://arxiv.org/search/?query=unizero+planning+world+models)** (2024)

---

## 20. Diffusion Models

### Landmark Papers
- **["Denoising Diffusion Probabilistic Models"](https://arxiv.org/abs/2006.11239)** - Ho et al. (2020)
  - **DDPM**: Breakthrough in generative modeling with diffusion
  
- **["Score-Based Generative Modeling through Stochastic Differential Equations"](https://arxiv.org/abs/2011.13456)** - Song et al. (2021)
  - Unifying diffusion and score-based models
  
- **["High-Resolution Image Synthesis with Latent Diffusion Models"](https://arxiv.org/abs/2112.10752)** - Rombach et al. (2022)
  - **Stable Diffusion**: Efficient latent diffusion

### Important Branch Papers
- **["Generative Modeling by Estimating Gradients of the Data Distribution"](https://arxiv.org/abs/1907.05600)** - Song & Ermon (2019)
- **["Improved Techniques for Training Score-Based Generative Models"](https://arxiv.org/abs/2006.09011)** - Song et al. (2020)

### SOTA Papers
- **["Critically-Damped Langevin Diffusion"](https://arxiv.org/search/?query=critically+damped+langevin+diffusion)** (2021)

---

## 21. Generative Models

### Landmark Papers
- **["Generative Adversarial Nets"](https://arxiv.org/abs/1406.2661)** - Goodfellow et al. (2014)
  - **GANs**: Revolutionary adversarial training framework
  
- **["Auto-Encoding Variational Bayes"](https://arxiv.org/abs/1312.6114)** - Kingma & Welling (2013)
  - **VAE**: Latent variable generative model
  
- **["Diffusion Models Beat GANs on Image Synthesis"](https://arxiv.org/abs/2105.05233)** - Dhariwal & Nichol (2021)

### Important Branch Papers
- **["Wasserstein GAN"](https://arxiv.org/abs/1701.07875)** - Arjovsky et al. (2017)
- **["Progressive Growing of GANs for Improved Quality, Stability, and Variation"](https://arxiv.org/abs/1710.10196)** - Karras et al. (2017)
- **["A Style-Based Generator Architecture for Generative Adversarial Networks"](https://arxiv.org/abs/1812.04948)** - Karras et al. (2018)
  - **StyleGAN**

---

## 22. Text-to-Video Generation

### Landmark Papers
- **["Make-A-Video: Text-to-Video Generation without Text-Video Data"](https://arxiv.org/abs/2209.14792)** - Singer et al. (2022)
  - Transfer text-to-image to text-to-video
  
- **["Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators"](https://arxiv.org/abs/2303.13439)** - Khachatryan et al. (2023)
  - Zero-shot video generation from image models

### SOTA Papers
- **["CogVideoX: Text-to-Video Diffusion Models with Expert Transformer"](https://arxiv.org/search/?query=cogvideox+text+to+video)** (2024)

---

## 23. Motion Planning and Behavior Planning

### Landmark Papers
- **["Sampling-Based Algorithms for Motion Planning: A Comparative Review"](https://arxiv.org/abs/1012.1161)** - Sucan et al. (2012)
  - Comprehensive overview of motion planning
  
- **["Rapidly-Exploring Random Trees: A New Tool for Path Planning"](http://msl.cs.uiuc.edu/~lavalle/papers/Lav98c.pdf)** - LaValle (1998)
  - **RRT**: Foundational sampling-based planner
  
- **["Probabilistic Roadmaps for Path Planning in High-Dimensional Configuration Spaces"](https://ieeexplore.ieee.org/document/280810)** - Kavraki et al. (1996)
  - **PRM**: Probabilistic roadmap method

### Important Branch Papers
- **["Sampling-based Algorithms for Optimal Motion Planning"](https://arxiv.org/abs/1105.1186)** - Karaman & Frazzoli (2011)
  - **RRT***: Optimality guarantees
- **["Informed RRT*: Optimal Sampling-based Path Planning Focused via Direct Sampling of an Admissible Ellipsoid"](https://arxiv.org/abs/1404.2247)** - Gammell et al. (2014)

### SOTA Papers
- **["EDMP: Ensemble-of-Costs-Guided Diffusion for Motion Planning"](https://arxiv.org/search/?query=edmp+ensemble+diffusion+motion+planning)** (2023)
- **["Robust Feedback Motion Planning via Contraction Theory"](https://arxiv.org/search/?query=robust+feedback+motion+planning+contraction)** (2023)

### Relevant Articles
- **["Task and Motion Planning: Recent Trends and Future Challenges"](https://arxiv.org/search/?query=task+motion+planning+survey)** (2023)
- **["Guiding Long-Horizon Task and Motion Planning with Vision Language Models"](https://arxiv.org/search/?query=vision+language+task+motion+planning)** (2024)

---

## 24. Agentic Systems

### Landmark Papers
- **["ReAct: Synergizing Reasoning and Acting in Language Models"](https://arxiv.org/abs/2210.03629)** - Yao et al. (2022)
  - Framework for agent reasoning and action
  
- **["Toolformer: Language Models Can Teach Themselves to Use Tools"](https://arxiv.org/abs/2302.04761)** - Schick et al. (2023)

### SOTA Papers
- **["Agentic Large Language Models: A Survey"](https://arxiv.org/search/?query=agentic+llm+survey)** (2025)
- **["Practical Considerations for Agentic LLM Systems"](https://arxiv.org/search/?query=practical+agentic+llm)** (2024)
- **["Agentic LLM-Based Robotic Systems for Real-World Applications"](https://arxiv.org/search/?query=agentic+llm+robotics)** (2025)

---

## 25. Speech Recognition and Transcription

### Landmark Papers
- **["wav2vec: Unsupervised Pre-Training for Speech Recognition"](https://arxiv.org/abs/1904.05862)** - Baevski et al. (2020)
  - Self-supervised speech representation learning

### Important Branch Papers
- **["wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations"](https://arxiv.org/abs/2006.11477)** - Baevski et al. (2020)
  - Major advancement in self-supervised speech

### SOTA Papers
- **["Robust Speech Recognition via Large-Scale Weak Supervision"](https://arxiv.org/abs/2212.04356)** - Radford et al. (2022)
  - **Whisper**: Multilingual speech recognition from weak supervision
  
- **["Whisper Turns Stronger: Augmenting Wav2Vec 2.0 for Superior ASR"](https://arxiv.org/search/?query=whisper+wav2vec+asr)** (2024)

---

## 26. Text-to-Speech (TTS)

### Landmark Papers
- **["Tacotron: Towards End-to-End Speech Synthesis"](https://arxiv.org/abs/1703.10135)** - Wang et al. (2017)
  - Sequence-to-sequence text-to-speech
  
- **["Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions"](https://arxiv.org/abs/1712.05884)** - Wang et al. (2017)
  - **Tacotron2**: Improved TTS with neural vocoder
  
- **["WaveNet: A Generative Model for Raw Audio"](https://arxiv.org/abs/1609.03499)** - Van Den Oord et al. (2016)
  - Foundational neural vocoder

### Important Branch Papers
- **["FastSpeech: Fast, Robust and Controllable Text-to-Speech"](https://arxiv.org/abs/1905.09263)** - Ren et al. (2019)
  - Non-autoregressive speech synthesis
  
- **["FastSpeech 2: Fast and High-Quality End-to-End Text to Speech"](https://arxiv.org/abs/2006.04558)** - Ren et al. (2020)

### SOTA Papers
- **["NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models"](https://arxiv.org/search/?query=naturalspeech+zero+shot+speech)** (2024)
- **["Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers"](https://arxiv.org/abs/2301.02111)** - Wang et al. (2023)
  - **VALL-E**: Neural codec-based TTS

### Relevant Articles
- **["A Comparative Study of Text-to-Speech Models and Vocoder Combinations"](https://arxiv.org/search/?query=comparative+tts+models+vocoder)** (2023)

---

## 27. Multi-Agent Systems

### Landmark Papers
- **["Cooperative Multi-Agent Learning: The State of the Art"](https://ieeexplore.ieee.org/document/1459520)** - Panait & Luke (2005)
  - Comprehensive survey on cooperative multi-agent learning
  
- **["Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments"](https://arxiv.org/abs/1706.02275)** - Lowe et al. (2017)
  - **MADDPG**: Multi-agent coordination

### SOTA Papers
- **["A Comprehensive Survey on Multi-Agent Cooperative Decision-Making"](https://arxiv.org/search/?query=multi+agent+cooperative+decision+making)** (2025)
- **["Multi-Agent AI: From Isolated Agents to Cooperative Ecosystems"](https://arxiv.org/search/?query=multi+agent+ai+ecosystems)** (2025)

---

## 28. LiDAR Point Cloud Processing and Mapping

### Landmark Papers
- **["PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation"](https://arxiv.org/abs/1612.00593)** - Qi et al. (2016)
  - Foundational work for point cloud processing
  
- **["PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space"](https://arxiv.org/abs/1706.02413)** - Qi et al. (2017)
  - Hierarchical learning on point clouds

### Important Branch Papers
- **["Spherical Frustum Sparse Convolution Network for LiDAR Point Cloud Semantic Segmentation"](https://arxiv.org/search/?query=spherical+frustum+sparse+convolution+lidar)** (2024)
- **["Real-time Semantic Segmentation of 3D LiDAR Point Cloud"](https://arxiv.org/search/?query=real+time+lidar+segmentation)** (2021)

### SOTA Papers
- **["3D Point Cloud-Based Place Recognition: A Survey"](https://arxiv.org/search/?query=point+cloud+place+recognition+survey)** (2024)
- **["Multi-scale Sparse Convolution and Point Convolution Adaptive Fusion for LiDAR Segmentation"](https://arxiv.org/search/?query=multi+scale+sparse+point+convolution+lidar)** (2025)

### Relevant Articles
- **["Analysis of Current Advancement in 3D Point Cloud Semantic Segmentation"](https://arxiv.org/search/?query=point+cloud+semantic+segmentation+analysis)** (2023)

---

## 29. Sensor Fusion

### Landmark Papers
- **["Probabilistic Robotics"](https://mitpress.mit.edu/9780262201629/probabilistic-robotics/)** - Thrun, Burgard & Fox (2005)
  - Foundational work on sensor fusion for robotics
  
- **["Kalman Filtering with Real-Time Applications"](https://link.springer.com/book/10.1007/978-1-4614-9674-5)** - Grewal & Andrews (2014)

### Important Branch Papers
- **["Multimodal Learning with Deep Boltzmann Machines"](https://arxiv.org/abs/1301.3568)** - Ngiam et al. (2011)
  - Latent variable algorithms for multimodal learning
  
- **["Robust Multi-Modal Sensor Fusion"](https://arxiv.org/search/?query=robust+multi+modal+sensor+fusion)** - Vellido et al. (2019)

### SOTA Papers
- **["When Pedestrian Detection Meets Multi-Modal Learning"](https://arxiv.org/search/?query=pedestrian+detection+multi+modal)** (2024)
- **["Multi-modal Sensor Fusion for Auto Driving Perception: A Survey"](https://arxiv.org/search/?query=sensor+fusion+autonomous+driving+survey)** (2022)
- **["CAFuser: Condition-Aware Multimodal Fusion for Robust Semantic Perception"](https://arxiv.org/search/?query=cafuser+multimodal+fusion)** (2025)
- **["Deep Learning-Based Multi-Modal Sensor Fusion for CSI Compression"](https://arxiv.org/search/?query=multi+modal+sensor+fusion+csi)** (2025)

### Relevant Articles
- **["Integrating Advanced Sensor Fusion with User-Centered Design"](https://arxiv.org/search/?query=sensor+fusion+design)** (2023)
- **["Multimodal Sensor Fusion in the Latent Representation Space"](https://arxiv.org/search/?query=multimodal+latent+representation)** (2022)

---

## Cross-Domain Overview

### Key Conferences for Publication
- **[CVPR](https://cvpr2025.thecvf.com/)** - Computer Vision and Pattern Recognition
- **[ICCV](https://iccv2025.thecvf.com/)** - International Conference on Computer Vision
- **[ECCV](https://eccv2024.ecva.net/)** - European Conference on Computer Vision
- **[NeurIPS](https://nips.cc/)** - Neural Information Processing Systems
- **[ICML](https://icml.cc/)** - International Conference on Machine Learning
- **[ICLR](https://iclr.cc/)** - International Conference on Learning Representations
- **[RSS](https://roboticsconference.org/)** - Robotics: Science and Systems
- **[IROS](https://www.iros2025.org/)** - Intelligent Robots and Systems
- **[ICRA](https://2025.icra.org/)** - International Conference on Robotics and Automation
- **[SIGGRAPH](https://www.siggraph.org/)** - Computer Graphics and Interactive Techniques

### Recommended Reading Order
1. **Foundations**: [Attention Is All You Need](https://arxiv.org/abs/1706.03762), [NeRF](https://arxiv.org/abs/2003.08934), [CLIP](https://arxiv.org/abs/2103.14030), [PointNet](https://arxiv.org/abs/1612.00593)
2. **Vision**: [AlexNet](https://papers.neurips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks), [ResNet](https://arxiv.org/abs/1512.03385), [ViT](https://arxiv.org/abs/2010.11929), [FCN](https://arxiv.org/abs/1411.4038), [U-Net](https://arxiv.org/abs/1505.04597)
3. **3D**: [3DGS](https://arxiv.org/abs/2308.04079), [PointNet++](https://arxiv.org/abs/1706.02413), SLAM papers
4. **Language**: [BERT](https://arxiv.org/abs/1810.04805), [GPT series](https://arxiv.org/abs/2005.14165)
5. **Multimodal**: [CLIP](https://arxiv.org/abs/2103.14030), VLM papers
6. **Applications**: Domain-specific papers in robotics, autonomous driving

---

*Last Updated: 2025-11-07*
*Research includes papers through 2025*
